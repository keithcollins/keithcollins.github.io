---
import BaseLayout from "../layouts/BaseLayout.astro";
---

<BaseLayout
  title="Good Forms by Keith Collins"
  description="Music and software by Good Forms/Keith Collins"
>
  <p>
    ‚û°Ô∏è <strong
      >Follow Good Forms on <a href="https://soundcloud.com/goodforms"
        >Soundcloud</a
      >, <a href="https://tiktok.com/@thegoodforms">TikTok</a> and <a
        href="https://x.com/thegoodforms">Twitter</a
      >.</strong>
  </p>

  <h2>Introducing my first Max for Live Device</h2>

  <img src="/images/m4l/demo1.png" />

  <p>My first M4L device (which I am currently calling Smush) allows you to load a sample and remove audio below a dB threshold that you set. It "smushes" the remaining audio segments together with smooth crossfades, which you also control.</p>
    
  <img src="/images/m4l/demo2.png" />

  <p>This creates a new, condensed version of the original sample that can be bounced to a new audio track.</p>

  <p>The device is built around a V8 JavaScript engine, providing a dynamic and responsive user interface for controlling the editing process.</p>

  <p>Here is a brief demo video:</p>

  <video controls width="335" style="max-width: 335px;">
    <source src="/images/m4l/smushtest.mp4" type="video/mp4" />
    Your browser does not support the video tag.
  </video>

  <div style="font-size:30px; line-height:1.4; margin: 20px 0 15px 0">Would you like to help beta-test this device? If so, <a href="https://docs.google.com/forms/d/e/1FAIpQLSfxVyWYxZrfpKM_Aa9UyU2P3QWhGbDlhsg35I5fMJsIyy99HA/viewform">please fill out this form!</a></div>

  <h2>Core Features</h2>

  <ul>
    <li>
      <strong>Silence Detection</strong>: Analyzes an audio sample to identify regions of silence based on a user-definable dB threshold.
    </li>
    <li>
      <strong>Audio Combining</strong>: Creates a new audio buffer containing only the parts of the original sample above the set threshold.
    </li>
    <li>
      <strong>Automatic Crossfading</strong>: Applies smooth equal-power or linear crossfades between the joined audio segments to prevent clicks and pops. The crossfading can also be turned off, so that the kept regions are combined without overlaps.
    </li>
    <li>
      <strong>Dynamic UI</strong>:
      <ul>
        <li>The top waveform display shows the original audio and highlights the detected silent regions.</li>
        <li>A draggable line on the waveform display allows the user to intuitively set the silence threshold.</li>
        <li>The combined audio is displayed in the lower waveform..</li>
      </ul>
    </li>
    <li>The combined audio can be currently be played back via MIDI notes.</li>
    <li>
      <strong>Configurable Parameters</strong>:
      <ul>
        <li><strong>Threshold</strong>: Sets the dB level below which audio is considered silent. The device intelligently suggests an initial threshold based on the audio's dynamics.</li>
        <li><strong>Min. Window</strong>: Defines the shortest duration of silence that will be kept.</li>
        <li><strong>Crossfade Curve</strong>: Allows switching between equal power, linear or no crossfade curves.</li>
        <li><strong>Crossfade Duration</strong>: Sets the total length of the crossfade.</li>
      </ul>
    </li>
  </ul>

  <img src="/images/m4l/patcher.png" />

  <hr />
  <h2>Development Log</h2>

  <p>
    I am keeping a log of my progress and I build this device, 
    to keep track of the changes as I go and, hopefully, to 
    help fellow developers. Please get in touch if you have questions 
    or suggestions!
  </p>

  <p>Here's a snapshot of the project statistics as of Feb. 9, 2026:</p>

  <p><strong>Total commits:</strong> 77</p>
  <p><strong>Most changed files:</strong></p>
  <ol>
    <li><code>index.js</code> - 56 commits, 353 lines (final)</li>
    <li>
      <code>v8ui.js</code> ‚Üí <code>mainGraphics.js</code> + <code
        >smushGraphics.js</code
      > - 21 commits total
    </li>
  </ol>
  <p><strong>Lines of code (final count):</strong></p>
  <ul>
    <li><code>index.js</code>: 353 lines</li>
    <li><code>state.js</code>: 216 lines</li>
    <li><code>smush.js</code>: 292 lines</li>
    <li><code>findAudioRegions.js</code>: 109 lines</li>
    <li><code>audioBouncer.js</code>: 380 lines</li>
    <li><code>bufferManager.js</code>: 120 lines</li>
    <li><code>maxObjectManager.js</code>: 265 lines</li>
    <li><code>mainGraphics.js</code>: 243 lines</li>
    <li><code>smushGraphics.js</code>: ~90 lines</li>
    <li><code>getBufferMinMax.js</code>: ~60 lines</li>
  </ul>
  <p><strong>Total:</strong> ~2,128 lines of JavaScript across 10 modules</p>
  <hr />

  
  <h2>February 8: Problems with audio bouncing</h2>
  <h3>Max pains</h3>
  <p>
    I am having a lot of trouble getting the path to the temporary project
    folder Ableton Live creates for unsaved Live Sets.
  </p>
  <p>
    At minimum, I would like to get the path to the user&#39;s Temporary Folder,
    which is set in Ableton Live &gt; Settings &gt; File &amp; Folder &gt;
    Temporary Folder. By default on Mac it is:
  </p>
  <p>~/Music/Ableton/Live Recordings/</p>
  <p>
    What I really want is the full path to the current Live Set in the case that
    the Set has not yet been saved:
  </p>
  <p>~/Music/Ableton/Live Recordings/2026-02-06 094518 Temp Project/</p>
  <p>
    If you create a new Live Set in Ableton Live, add audio or MIDI to a track,
    then right-click on your clip and select &quot;Bounce Track in Place&quot;
    or &quot;Bounce to New Track,&quot; Ableton saves the bounced audio to:
  </p>
  <p>
    ~/Music/Ableton/Live Recordings/2026-02-06 094518 Temp
    Project/Samples/Processed/Bounce
  </p>
  <p>
    I simply want to follow that pattern in the device I am working on. Since my
    device allows the user to bounce audio from the device&#39;s buffer to a new
    audio track. It works fine if the Live Set has been saved, because I can get
    the path to the project folder and save the audio there. But if the Live Set
    has not yet been saved, I want to save the bounced audio the same way
    Ableton does by default.
  </p>
  <p>I do not want to save to the Max temporary folder, which for me is:</p>
  <p>
    ~/Library/Application Support/Cycling &#39;74/Max 9/Settings/temp64-live
  </p>
  <h3>Clever solution</h3>
  <p>
    I finally found a solution. It&#39;s very round-about, and if someone has a
    cleaner way to do this, please tell me. But here is what is currently
    working for me (using Live 12 and Max 9, V8 JavaScript):
  </p>
  <p>
    Basically, I used Clip.crop() to trigger Live&#39;s native file management,
    which reveals the temp folder path. When you call clip.crop() on an audio
    clip, Live creates a new consolidated audio file in its managed folder
    structure. By reading the clip&#39;s file_path property before and after the
    crop operation, you can extract Live&#39;s temporary project folder path.
  </p>
  <ul>
    <li>
      <p>First, my device saves its output audio to Max&#39;s temp folder.</p>
    </li>
    <li>
      <p>
        I use the LiveAPI to create a track and load my audio file into a clip.
      </p>
    </li>
    <li>
      <p>I use a Task with a delay to ensure the clip is fully created.</p>
    </li>
  </ul>
  <pre
    set:html={`<code class="language-js">const discoveryTask = new Task(function() {
      const clip = new LiveAPI(\`live_set tracks \${trackIndex} arrangement_clips 0\`);
      
      if (clip.id == 0) {
          error(&quot;Could not access clip\\n&quot;);
          return;
      }
      
      // Continue to next step...
  }, this);

  discoveryTask.schedule(100); // 100ms delay
  </code>`}
  />
  <ul>
    <li>
      I trigger the crop operation and wait for Live to create the new file,
      then get the path to that file. Now the file lives in ~/Music/Ableton/Live
      Recordings/2026-02-06 185736 Temp Project/Samples/Processed/Crop which
      works for my purposes, and I now have the path to the temporary project
      folder, which I can use if the user bounces a new audio clip out of the
      device.
    </li>
  </ul>
  <pre
    set:html={`<code class="language-js">// Call crop - this triggers Live's file management

  clip.call(&quot;crop&quot;);
  // Wait for crop to complete

  const checkTask = new Task(function() {
    const newPath = clip.get(&quot;file_path&quot;);

    post(\`New path: \${newPath[0]}\\n\`);
    // Continue to extraction...
  }, this);

  checkTask.schedule(100); // 100ms delay for crop operation
  </code>`}
  />
  <h3>Audio bouncer extracted from index.js</h3>
  <p>
    Now that this works, I have extracted all bounce/export functionality into
    its own module.
  </p>
  <p>
    <strong>Created <code>audioBouncer.js</code> (380 lines)</strong> - A complete
    audio export system:
  </p>
  <ul>
    <li>Multi-format support (WAV, AIFF, FLAC)</li>
    <li>Bit depth options (16/24/32-bit)</li>
    <li>Sample rate conversion</li>
    <li>Progress tracking</li>
    <li>Error handling</li>
    <li>File path management</li>
  </ul>
  <p>
    <strong><code>index.js</code> shrunk dramatically:</strong> 181 lines removed,
    replaced with:
  </p>
  <pre
    set:html={`import { AudioBouncer } from &#39;./audioBouncer.js&#39;;
  const bouncer = new AudioBouncer();
  bouncer.bounce(buffer, filepath, options);
  `}
  />
  <hr />
  
  
  <h2>February 3: Interactive threshold control</h2>
  <h3>Mouse interactions</h3>
  <p><strong>New capabilities:</strong></p>
  <ul>
    <li>Click-and-drag threshold adjustment</li>
    <li>Visual feedback during interaction</li>
    <li>Smooth value updates to UI controls</li>
  </ul>
  <p>
    <code>mainGraphics.js</code> and <code>smushGraphics.js</code> got synced interaction
    patterns.
  </p>
  <p>
    <code>state.js</code> can track interaction state: <code>isHovering</code>, <code
      >isDragging</code
    >, <code>dragStartY</code>, etc.
  </p>
  <h3>Hover &amp; cursor</h3>
  <p>Refined the hover behavior.</p>
  <p><strong>Polish details:</strong></p>
  <ul>
    <li>Worked on hover state rendering in <code>mainGraphics.js</code></li>
    <li>TODO: Cursor changes to indicate draggability</li>
    <li>Smooth transitions between states</li>
  </ul>
  <h3>Line dragging</h3>
  <p>Fine-tuned the drag interaction to make it feel natural.</p>
  <hr />


  <h2>January 29: Crossfade visualization</h2>
  <h3>Merge points</h3>
  <p>Started visualizing where audio regions get joined together.</p>
  <p>
    <strong>New feature in <code>smushGraphics.js</code>:</strong> Draw markers at
    crossfade points so you can see exactly where the audio is being spliced.
  </p>
  <p><strong>Visual design:</strong></p>
  <ul>
    <li>Equal-power crossfades show as smooth S-curves</li>
    <li>Linear crossfades show as straight diagonal lines</li>
    <li>Markers at start/end of each crossfade region</li>
  </ul>
  <p>
    Now you can <em>see</em> how the audio is being blended. But... it&#39;s not as
    helpful as I expected. Especially for longer audio, it really just adds noise
    to the output waveform. Will likely drop it.
  </p>
  <p>Documenting the math behind equal-power crossfading:</p>
  <pre><code class="language-javascript">// Linear: 3dB dip in the middle
  outA = inA * (1 - position);
  outB = inB * position;

  // Equal-power: constant perceived loudness
  outA = inA * Math.cos(position * Math.PI / 2);
  outB = inB * Math.sin(position * Math.PI / 2);
  </code></pre>
  <p>
    <strong>Why equal-power?</strong> Human perception of loudness isn&#39;t linear.
    Equal-power curves compensate for this, making crossfades sound smooth and natural.
  </p>
  <h3>Threshold line interaction</h3>
  <p>
    Made the threshold line interactive. You can now click and drag it up and
    down to adjust the silence threshold in real-time.
  </p>
  <p><strong>Implementation details (<code>mainGraphics.js</code>):</strong></p>
  <ul>
    <li>
      Mouse events in v8ui: <code>onclick</code>, <code>ondrag</code>, <code
        >onidleout</code>
    </li>
    <li>Convert pixel Y position to dB value</li>
    <li>Update state</li>
    <li>Redraw graphics</li>
    <li>Trigger reprocessing</li>
  </ul>
  <p><code>smushGraphics.js</code> also got interaction improvements.</p>
  <hr />
  
  
  <h2>January 27: Polishing üíé</h2>
  <h3>UI Updates (Jan 25, 14:36)</h3>
  <ul>
    <li>
      Added crossfade type selector with custom icons: for equal power, linear
      fade and no fade.
    </li>
    <li>Updated color scheme based on Illustrator mockups</li>
  </ul>
  <p><code>state.js</code> grew to accommodate new UI parameters.</p>
  <p>
    <strong>Design detail:</strong> Exported <code>Granulator III.pdf</code> from
    Max for reference. Studying how Ableton&#39;s flagship M4L devices handle UI helped
    inform our design decisions.
  </p>
  <h3>State simplification</h3>
  <p>
    Refactored <code>state.js</code> down from 222 lines to 97. Removed 125 lines
    of cruft that accumulated during development.
  </p>
  <h3>Bounce feature</h3>
  <p>
    Added audio export functionality. You can now render the smushed audio to a
    new audio file.
  </p>
  <p><code>index.js</code> is handling:</p>
  <ul>
    <li>File path selection</li>
    <li>Buffer-to-disk writing</li>
    <li>Progress feedback</li>
    <li>Error handling</li>
  </ul>
  <h3>Trimming fat</h3>
  <p>
    Huge simplification of <code>state.js</code>, and <code>index.js</code> got a
    165-line overhaul improving message handling and state synchronization.
  </p>
  <h3>Reset issues</h3>
  <p>
    It&#39;s important that the user can drop a new audio clip into the device
    at any time, even if audio was previously loaded. So it&#39;s also important
    that when that happens, the device resets.
  </p>
  <p>
    <strong>The problem:</strong> State wasn&#39;t fully clearing when it got new
    audio. Some UI elements remembered old values, waveforms showed ghost data, etc.
  </p>
  <h3>Buffer stuff</h3>
  <p>Proper sequencing of buffer operations:</p>
  <ol>
    <li>Stop transport (prevents clicks)</li>
    <li>Clear old buffer</li>
    <li>Initialize new buffer</li>
    <li>Update UI</li>
    <li>Notify graphics layers</li>
    <li>Resume transport if needed</li>
  </ol>
  <h3>Floor UI</h3>
  <p>
    Added an experimental &quot;floor&quot; parameter that allows the user to
    adjust the visible floor of the input audio, essentially zooming in
    vertically. It works, but it doesn&#39;t feel super helpful.
  </p>
  <hr />


  <h2>January 24: Good progress</h2>

  <h3>Design Iterations:</h3>
  <img src="/images/m4l/sketch-2026-01-24.png" /><br>
  <img src="/images/m4l/sketch-2026-01-25.png" /><br>

  <h3>Working on device reset</h3>
  <p>Complete rewrite of the reset functionality using the new state system.</p>
  <p>
    Deleted <code>v8ui.js</code>, fully switched to <code>mainGraphics.js</code> and
    <code>smushGraphics.js</code>, each of which handles painting for their
    respective v8ui objects.
  </p>
  <p>Split graphics rendering into two specialized files:</p>
  <ul>
    <li><code>mainGraphics.js</code> handles the main buffer visualization</li>
    <li>
      <code>smushGraphics.js</code> handles the smushed buffer + crossfade overlays
    </li>
  </ul>
  <h3>Initialization refinement</h3>
  <p>
    Fixed a subtle race condition: the <code>bufferInit</code> flag was being set
    too early in the initialization sequence, causing occasional glitches when loading
    audio quickly.
  </p>
  <p>
    <strong>The fix:</strong> Move the flag to the very end of <code
      >initBuffer()</code
    >, after ALL initialization is complete.
  </p>
  <h3>Looking good</h3>
  <p>
    Everything is working pretty well. Reset button: ‚úÖ. Buffer loading: ‚úÖ.
    Silence detection: ‚úÖ. Crossfades: ‚úÖ. UI updates: ‚úÖ.
  </p>
  <h3>Design work</h3>
  <p>More UI sketching:</p>
  <hr />


  <h2>January 23: (No more DataManager)</h2>
  <h3>DataManager ‚Üí State.js</h3>
  <p>
    Big decision: DataManager isn&#39;t working out. The Dictionary-based
    persistence is causing race conditions and state desync issues.
  </p>
  <p>
    Max&#39;s Dictionary objects are great for patchers, but in JS they add
    unnecessary complexity. Switched to a plain object and Global for
    cross-script communication.
  </p>
  <h3>New stuff</h3>
  <p><strong>Created three new files:</strong></p>
  <ul>
    <li>
      <strong><code>state.js</code></strong> (201 lines) - Global-based state management
    </li>
    <li>
      <strong><code>mainGraphics.js</code></strong> (138 lines) - Main waveform rendering
      logic
    </li>
    <li>
      <strong><code>smushGraphics.js</code></strong> (61 lines) - Smushed waveform
      rendering logic
    </li>
  </ul>
  <p><strong>New architecture:</strong></p>
  <pre
    set:html={`<code class="language-javascript">// state.js creates a device-specific Global
  const stateGlobal = new Global(\`smush_state_\${deviceId}\`);

  // Any script can now access/modify state
  import { state } from './state.js';
  state.thresholdDb = -40;
  </code>`}
  />
  <p>
    <strong>Why Global?</strong> Unlike Dictionaries, Globals are just JavaScript
    objects living in Max&#39;s JS engine. Fast, simple, and they work exactly how
    you&#39;d expect objects to work.
  </p>
  <hr />


  <h2>January 22: Snapshot, Playhead &amp; RMS‚ÜíPeak</h2>
  <h3>Snapshot Feature</h3>
  <p>Added the ability to capture the current device state for recall.</p>
  <p>
    <strong>Refactor:</strong> Simplified <code>findAudioRegions.js</code> by removing
    redundant code.
  </p>
  <h3>Playhead Visualization</h3>
  <p>
    Rebuilt the playback playhead from scratch. Now you can see exactly where
    you are in the waveform during playback.
  </p>
  <p><strong>Technical approach:</strong></p>
  <ul>
    <li>Listen to Max&#39;s transport position</li>
    <li>Convert to buffer samples</li>
    <li>Draw a vertical line in v8ui</li>
    <li>Update at ~30fps for smooth animation</li>
  </ul>
  <h3>V8UI for Creation Waveform</h3>
  <p>
    Added a second v8ui overlay specifically for the smushed buffer
    visualization. Now both <code>---main</code> and <code>---smush</code> have their
    own UI layers.
  </p>
  <h3>dB-Linear Slider</h3>
  <p>Threshold control got a major upgrade. Worked on some UI mockups.</p>
  <h3>Plot~ Integration Attempt</h3>
  <p>
    Trying to figure out if <code>plot~</code> would be better than <code
      >waveform~</code
    > for visualization.
  </p>
  <h3>horizontal line working, now switching from RMS to peak</h3>
  <p>
    Added the threshold visualization: a draggable horizontal line showing the
    current silence threshold in dB.
  </p>
  <p>
    <strong>The problem:</strong> The device was using RMS (root-mean-square) for
    silence detection, but Max&#39;s <code>waveform~</code> and <code
      >plot~</code
    > objects display peak values. This meant the threshold line didn&#39;t align
    with the visual waveform. Confusing!
  </p>
  <h3>implemented peak, lookin for leak</h3>
  <p>
    Switched to peak-based detection. Now the silence threshold visually aligns
    with what you see in the waveform.
  </p>
  <p>
    <strong>But...</strong> memory leak detected. After processing several buffers,
    Max&#39;s memory usage kept climbing. üêõ
  </p>
  <p>
    <strong>The culprit:</strong> Creating new <code>Buffer</code> objects without
    freeing old ones. Each buffer is a peer object that Max has to manage. If you
    don&#39;t call <code>freepeer()</code>, they accumulate in memory.
  </p>
  <hr />


  <h2>January 21: UI Polish &amp; Peak Detection</h2>

  <h3>Design Iterations:</h3>
  <img src="/images/m4l/proto-2026-01-20.png" /><br>
  <img src="/images/m4l/proto-2026-01-22.png" /><br>
  <img src="/images/m4l/sketch-2026-01-20.png" /><br>
  <img src="/images/m4l/sketch-2026-01-21.png" /><br>
  <img src="/images/m4l/sketch-2026-01-22.png" /><br>
  <img src="/images/m4l/sketch-2026-01-22-2.png" /><br>

  <h3>Design Exploration</h3>
  <p>
    Started thinking about how the threshold line should be drawn.
  </p>
  <h3>Dropping Async</h3>
  <p>
    Something broke in the async experiment. Reverted changes to <code
      >findAudioRegions.js</code
    > and <code>getBufferMinMax.js</code>.
  </p>
  <p>
    <strong>Lesson learned:</strong> Async in Max is tricky. The scheduler model is
    different from Node.js. Reverted to sync processing for stability.
  </p>
  <h3>MIDI Integration</h3>
  <p>Now you can trigger the smushed audio with MIDI notes.</p>
  <h3>State Management Overhaul</h3>
  <p>
    Three late-night commits fixing persistent state issues. The waveforms
    weren&#39;t resetting properly when loading new files.
  </p>
  <p>
    <strong>The bug:</strong>
    <code>v8ui</code> was holding onto stale buffer references.
  </p>
  <p>
    <strong>The fix:</strong> Added explicit refresh messages to <code
      >v8ui.js</code
    > whenever buffers change. Also improved the lifecycle: init ‚Üí load ‚Üí paint ‚Üí
    clear ‚Üí repeat.
  </p>
  <h3>Min/Max Optimization</h3>
  <p>
    Improved <code>getBufferMinMax.js</code> with smarter caching. If you&#39;re drawing
    the same region twice, don&#39;t recalculate.
  </p>
  <hr />


  <h2>January 17</h2>

  <h3>Design Iterations</h3>

  <img src="/images/m4l/proto-2026-01-17.png" /><br>
  <img src="/images/m4l/proto-2026-01-18.png" /><br>
  <img src="/images/m4l/proto-2026-01-18-2.png" /><br>

  <h3>Performance Refactor</h3>
  <p>
    Tried an async version of the smush script. TypedArrays and frame-based
    processing to handle large files without blocking the Max scheduler.
  </p>
  <p>
    <strong>Key insight:</strong> Max&#39;s <code>poke~</code> is synchronous and
    can choke on big buffers. Solution: process in chunks, use <code>Task</code> for
    yielding back to the scheduler. But it makes the UI slow and clunky, so may ditch.
  </p>
  <h3>BufferManager Class</h3>
  <p>
    Created <code>bufferManager.js</code> (174 lines) to handle buffer lifecycle management:
  </p>
  <ul>
    <li>Automatic <code>freepeer()</code> cleanup to prevent memory leaks</li>
    <li>Centralized buffer creation and reference caching</li>
    <li>Two-buffer coordination (main ‚Üî smush)</li>
  </ul>
  <p>
    One class owns all buffer operations. <code>index.js</code> just says &quot;give
    me the main buffer&quot; and doesn&#39;t worry about the messy details.
  </p>
  <h3>Performance Tools</h3>
  <p>
    Built <code>getBufferMinMax.js</code>, a utility to quickly find min/max
    values in a buffer region for visualization scaling. Uses TypedArray <code
      >peek()</code
    > for fast traversal.
  </p>
  <p>
    <strong>Optimization:</strong> Instead of checking every single sample for waveform
    display, we sample strategically based on pixel width. If the waveform is 500
    pixels wide, we don&#39;t need to check all 2 million samples.
  </p>
  <h3>DataManager Introduction</h3>
  <p>
    New <code>dataManager.js</code> to centralize state. All the device parameters‚Äîthreshold,
    crossfade times, min region size‚Äînow live in one managed object.
  </p>
  <p><strong>Design pattern:</strong> Dictionary-based data persistence.</p>
  <h3>MaxObjectManager</h3>
  <p>
    The modular architecture saga continues with <code>maxObjectManager.js</code
    > (250 lines)‚Äîa caching layer for Max objects.
  </p>
  <p>
    <strong>Problem solved:</strong> Constantly calling <code
      >this.patcher.getnamed(&quot;some_object&quot;)</code
    > is expensive. This manager gets each object reference ONCE and caches it.
  </p>
  <pre><code class="language-javascript">// Old way (called every paint frame):
  const waveform = this.patcher.getnamed(&quot;waveform_display&quot;);

  // New way (cached):
  const waveform = maxObjects.get(&quot;waveform_display&quot;);
  </code></pre>
  <p>UI redesign too, with somewhat better visual hierarchy.</p>
  <hr />


  <h2>January 15</h2>

  <p>First real commit with original core files:</p>
  <ul>
    <li>
      <strong><code>index.js</code></strong> (242 lines) - Main entry point and orchestrator
    </li>
    <li>
      <strong><code>smush.js</code></strong> (209 lines) - Core audio processing logic
    </li>
    <li>
      <strong><code>findAudioRegions.js</code></strong> (71 lines) - Silence detection
      algorithm
    </li>
    <li>
      <strong><code>v8ui.js</code></strong> (119 lines) - Custom UI rendering with
      Max&#39;s v8ui
    </li>
    <li>
      <strong><code>Smush.amxd</code></strong> - The Max for Live device file itself
    </li>
    <li><strong><code>README.md</code></strong> - Initial documentation</li>
  </ul>
  <p><strong>Technical decisions made:</strong></p>
  <ul>
    <li>V8 JavaScript engine for modern ES6+ support</li>
    <li>
      Module system with CommonJS imports/exports for clean separation of
      concerns
    </li>
    <li>Custom <code>v8ui</code> overlays on native Max waveform objects</li>
  </ul>
  <h3>Two-Buffer Architecture</h3>
  <p>Early realization: we need two buffers, not one:</p>
  <ul>
    <li><code>---main</code>: The original, untouched audio (sacred!)</li>
    <li><code>---smush</code>: Where we do our destructive edits</li>
  </ul>
  <p>This way, you can always reset back to the original.</p>
  <h3>Stabilization</h3>
  <ul>
    <li>Improved initialization reliability</li>
    <li>Core audio processing refined</li>
    <li>Audio playback working</li>
    <li>
      The device is somewhat working. You can drop in audio, smush it, and hear
      the result.
    </li>
  </ul>
  <p>
    By evening: <strong>finally fixed buffer clear</strong> - The reset button actually
    works now. This involved understanding Max&#39;s buffer lifecycle and when to
    call <code>clear()</code> vs reassigning samples.
  </p>
  <h3>UI &amp; Control Layer</h3>
  <ul>
    <li>Added transport controls</li>
    <li>Created proper button layouts for load, reset, smush, and bounce</li>
  </ul>
  <hr />


  <h2>January 5-7</h2>

  <p>Getting started with the Max patcher, exploring possibilities:</p>

  <img src="/images/m4l/proto-2026-01-05.png" /><br>
  <img src="/images/m4l/proto-2026-01-06.png" /><br>
  <img src="/images/m4l/proto-2026-01-07.png" />

</BaseLayout>

<style>
  pre {
    background: #f4f4f4;
    border: 1px solid #ddd;
    border-radius: 4px;
    padding: 1rem;
    overflow-x: auto;
  }
  code {
    background: #f4f4f4;
    padding: 0.2rem 0.4rem;
    border-radius: 3px;
    font-family: "Monaco", "Courier New", monospace;
  }
  pre code {
    background: none;
    padding: 0;
  }
  table {
    border-collapse: collapse;
    width: 100%;
    margin: 1rem 0;
  }
  th,
  td {
    border: 1px solid #ddd;
    padding: 0.5rem;
    text-align: left;
  }
  th {
    background: #f4f4f4;
  }
</style>
